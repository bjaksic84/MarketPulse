{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9a3cf8",
   "metadata": {},
   "source": [
    "# 02 — Feature Engineering\n",
    "\n",
    "**MarketPulse Phase 1**\n",
    "\n",
    "This notebook demonstrates and visualizes all 60 features we compute:\n",
    "1. **Technical indicators** — trend, momentum, volatility, volume (33 features)\n",
    "2. **Return-based features** — lagged returns, rolling stats, risk metrics (27 features)\n",
    "3. Feature correlations and redundancy analysis\n",
    "4. Feature importance preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0558e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from src.data.market_config import load_market_config\n",
    "from src.data.fetcher import YFinanceFetcher\n",
    "from src.data.preprocessing import preprocess_ohlcv\n",
    "from src.features.technical import compute_technical_indicators, get_feature_names\n",
    "from src.features.returns import compute_return_features, get_return_feature_names\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a064373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and preprocess AAPL\n",
    "config = load_market_config('stocks')\n",
    "fetcher = YFinanceFetcher(market_config=config)\n",
    "\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.now() - timedelta(days=5*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "raw = fetcher.fetch('AAPL', start=start_date, end=end_date)\n",
    "df = preprocess_ohlcv(raw, market_config=config)\n",
    "print(f\"Preprocessed: {len(df)} rows, columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f833e8e",
   "metadata": {},
   "source": [
    "## 1. Technical Indicators\n",
    "\n",
    "We compute 5 groups of indicators using pandas-ta: **trend**, **momentum**, **volatility**, **volume**, and **custom** cross-indicator features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_technical_indicators(df)\n",
    "\n",
    "tech_features = get_feature_names()\n",
    "present = [f for f in tech_features if f in df.columns]\n",
    "missing = [f for f in tech_features if f not in df.columns]\n",
    "\n",
    "print(f\"Technical features computed: {len(present)}/{len(tech_features)}\")\n",
    "if missing:\n",
    "    print(f\"Missing (data-dependent): {missing}\")\n",
    "print(f\"\\nAll technical features: {present}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500c029",
   "metadata": {},
   "source": [
    "### 1.1 Trend Indicators — SMA, EMA, MACD\n",
    "\n",
    "Moving averages smooth out price noise. The MACD captures the momentum of the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2caaedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.tail(252)  # Last year\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True,\n",
    "                                gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "# Price with SMAs\n",
    "ax1.plot(df_plot.index, df_plot['close'], label='Close', color='black', linewidth=1.5)\n",
    "ax1.plot(df_plot.index, df_plot['sma_20'], label='SMA 20', alpha=0.8)\n",
    "ax1.plot(df_plot.index, df_plot['sma_50'], label='SMA 50', alpha=0.8)\n",
    "ax1.plot(df_plot.index, df_plot['sma_200'], label='SMA 200', alpha=0.8, linestyle='--')\n",
    "ax1.fill_between(df_plot.index, df_plot['bb_lower'], df_plot['bb_upper'],\n",
    "                  alpha=0.1, color='blue', label='Bollinger Bands')\n",
    "ax1.set_ylabel('Price ($)')\n",
    "ax1.set_title('AAPL — Trend Indicators')\n",
    "ax1.legend(loc='upper left', fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# MACD\n",
    "ax2.plot(df_plot.index, df_plot['macd'], label='MACD', color='blue')\n",
    "ax2.plot(df_plot.index, df_plot['macd_signal'], label='Signal', color='orange')\n",
    "colors = ['green' if v >= 0 else 'red' for v in df_plot['macd_hist']]\n",
    "ax2.bar(df_plot.index, df_plot['macd_hist'], color=colors, alpha=0.5, width=1)\n",
    "ax2.axhline(0, color='gray', linewidth=0.5)\n",
    "ax2.set_ylabel('MACD')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c9246",
   "metadata": {},
   "source": [
    "### 1.2 Momentum Indicators — RSI, Stochastic, CCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# RSI\n",
    "axes[0].plot(df_plot.index, df_plot['rsi_14'], color='purple', linewidth=1)\n",
    "axes[0].axhline(70, color='red', linestyle='--', alpha=0.5, label='Overbought (70)')\n",
    "axes[0].axhline(30, color='green', linestyle='--', alpha=0.5, label='Oversold (30)')\n",
    "axes[0].fill_between(df_plot.index, 30, 70, alpha=0.05, color='gray')\n",
    "axes[0].set_ylabel('RSI (14)')\n",
    "axes[0].set_title('Momentum Indicators')\n",
    "axes[0].legend(fontsize=8)\n",
    "axes[0].set_ylim(0, 100)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Stochastic\n",
    "axes[1].plot(df_plot.index, df_plot['stoch_k'], label='%K', color='blue')\n",
    "axes[1].plot(df_plot.index, df_plot['stoch_d'], label='%D', color='orange')\n",
    "axes[1].axhline(80, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].axhline(20, color='green', linestyle='--', alpha=0.5)\n",
    "axes[1].set_ylabel('Stochastic')\n",
    "axes[1].legend(fontsize=8)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# CCI\n",
    "axes[2].plot(df_plot.index, df_plot['cci_20'], color='teal', linewidth=1)\n",
    "axes[2].axhline(100, color='red', linestyle='--', alpha=0.5)\n",
    "axes[2].axhline(-100, color='green', linestyle='--', alpha=0.5)\n",
    "axes[2].set_ylabel('CCI (20)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7543e36",
   "metadata": {},
   "source": [
    "### 1.3 Volatility — Bollinger Bands, ATR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3515f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Bollinger Band Width — measures volatility expansion/contraction\n",
    "ax1.plot(df_plot.index, df_plot['bb_width'], color='orange', linewidth=1)\n",
    "ax1.set_ylabel('BB Width')\n",
    "ax1.set_title('Volatility Indicators')\n",
    "ax1.axhline(df_plot['bb_width'].mean(), color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ATR as % of price — comparable across different price levels\n",
    "ax2.plot(df_plot.index, df_plot['atr_pct'] * 100, color='red', linewidth=1)\n",
    "ax2.set_ylabel('ATR (% of Price)')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.axhline(df_plot['atr_pct'].mean() * 100, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc10c5",
   "metadata": {},
   "source": [
    "## 2. Return-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ca69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_return_features(df)\n",
    "\n",
    "ret_features = get_return_feature_names()\n",
    "present_ret = [f for f in ret_features if f in df.columns]\n",
    "print(f\"Return features computed: {len(present_ret)}/{len(ret_features)}\")\n",
    "print(f\"\\nAll return features: {present_ret}\")\n",
    "print(f\"\\nTotal feature count: {len(present) + len(present_ret)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94238828",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Lagged returns (1d vs 5d vs 20d)\n",
    "for col, label, color in [('ret_1d', '1-day', 'blue'), ('ret_5d', '5-day', 'green'), ('ret_20d', '20-day', 'red')]:\n",
    "    axes[0, 0].hist(df[col].dropna(), bins=60, alpha=0.5, label=label, density=True)\n",
    "axes[0, 0].set_title('Lagged Return Distributions')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_xlabel('Return')\n",
    "\n",
    "# Rolling volatility\n",
    "df_tail = df.tail(504)\n",
    "for col, label in [('vol_5d', '5-day'), ('vol_10d', '10-day'), ('vol_20d', '20-day')]:\n",
    "    axes[0, 1].plot(df_tail.index, df_tail[col], label=label, alpha=0.8)\n",
    "axes[0, 1].set_title('Rolling Volatility')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Z-score (mean reversion signal)\n",
    "axes[1, 0].plot(df_tail.index, df_tail['zscore_20d'], label='20d z-score', color='teal')\n",
    "axes[1, 0].axhline(2, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].axhline(-2, color='green', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].axhline(0, color='gray', linewidth=0.5)\n",
    "axes[1, 0].set_title('Z-Score (Mean Reversion Signal)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling max drawdown\n",
    "axes[1, 1].plot(df_tail.index, df_tail['max_dd_20d'], label='20d MDD', color='red')\n",
    "axes[1, 1].plot(df_tail.index, df_tail['max_dd_60d'], label='60d MDD', color='darkred')\n",
    "axes[1, 1].set_title('Rolling Maximum Drawdown')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('AAPL — Return-Based Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc4735",
   "metadata": {},
   "source": [
    "## 3. Feature Correlation Analysis\n",
    "\n",
    "Highly correlated features provide redundant information. We check for multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c06cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all feature columns\n",
    "all_features = present + present_ret + ['returns', 'log_returns', 'volume_norm']\n",
    "all_features = [f for f in all_features if f in df.columns]\n",
    "\n",
    "corr_matrix = df[all_features].dropna().corr()\n",
    "\n",
    "# Find highly correlated pairs (|r| > 0.9)\n",
    "high_corr = []\n",
    "for i in range(len(corr_matrix)):\n",
    "    for j in range(i+1, len(corr_matrix)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            high_corr.append((\n",
    "                corr_matrix.index[i], \n",
    "                corr_matrix.columns[j], \n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "print(f\"Feature pairs with |correlation| > 0.9: {len(high_corr)}\")\n",
    "print(\"\\nThese are candidates for removal during feature selection:\")\n",
    "for f1, f2, r in sorted(high_corr, key=lambda x: abs(x[2]), reverse=True)[:15]:\n",
    "    print(f\"  {f1:25s} ↔ {f2:25s}  r = {r:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full correlation heatmap (clustered)\n",
    "fig, ax = plt.subplots(figsize=(18, 16))\n",
    "sns.heatmap(corr_matrix, cmap='RdBu_r', center=0, vmin=-1, vmax=1,\n",
    "            xticklabels=True, yticklabels=True, ax=ax,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "ax.set_title('Feature Correlation Matrix (All 60 Features)', fontsize=14)\n",
    "plt.xticks(fontsize=7, rotation=90)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a020464",
   "metadata": {},
   "source": [
    "## 4. Feature Coverage & NaN Analysis\n",
    "\n",
    "Some features need a warmup period (e.g., SMA 200 needs 200 days). We check how many valid rows each feature has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d988b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN count per feature (sorted by most NaN)\n",
    "nan_counts = df[all_features].isnull().sum().sort_values(ascending=False)\n",
    "nan_pct = nan_counts / len(df) * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "nan_pct.plot(kind='barh', ax=ax, color='coral')\n",
    "ax.set_xlabel('% Missing (NaN)')\n",
    "ax.set_title('Feature Missing Values — Warmup Period Impact')\n",
    "ax.axvline(5, color='red', linestyle='--', label='5% threshold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal rows: {len(df)}\")\n",
    "print(f\"Rows with ALL features valid: {df[all_features].dropna().shape[0]}\")\n",
    "print(f\"Data lost to warmup: {len(df) - df[all_features].dropna().shape[0]} rows \"\n",
    "      f\"({(1 - df[all_features].dropna().shape[0]/len(df)):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8899ec",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **60 features** are computed per ticker — 33 technical + 27 return-based.\n",
    "2. Some features are **highly correlated** (e.g., SMA 20 ≈ BB mid, ret_1d ≈ returns). Feature selection in the modelling phase will prune these.\n",
    "3. **Warmup period**: The longest indicator (SMA 200) needs 200 days. After dropping NaN rows, we lose ~16% of data — this is expected and acceptable with 5 years of history.\n",
    "4. **Volatility features** (ATR, rolling vol, BB width) cluster together, as do **momentum features** (RSI, stochastic, MACD). This suggests natural feature groupings.\n",
    "\n",
    "Next: Notebook 03 — Modelling (walk-forward training, evaluation, SHAP analysis)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

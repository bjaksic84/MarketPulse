{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f988d24",
   "metadata": {},
   "source": [
    "# 05 — Feature Selection & Hyperparameter Tuning\n",
    "\n",
    "This notebook walks through:\n",
    "1. Feature selection (mutual info, importance, correlation filter)\n",
    "2. Hyperparameter optimization with Optuna (Bayesian / TPE)\n",
    "3. Comparing default vs tuned model performance\n",
    "4. Visual analysis of tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b1211",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.fetcher import YFinanceFetcher\n",
    "from src.data.preprocessing import preprocess_ohlcv\n",
    "from src.features.technical import compute_technical_indicators\n",
    "from src.features.returns import compute_return_features\n",
    "from src.features.labels import generate_labels, get_clean_features_and_labels\n",
    "from src.data.market_config import load_market_config, load_strategy_config\n",
    "\n",
    "# Setup\n",
    "TICKER = 'AAPL'\n",
    "market_config = load_market_config('stocks')\n",
    "strategy_config = load_strategy_config('short_term')\n",
    "\n",
    "# Fetch & build features\n",
    "fetcher = YFinanceFetcher()\n",
    "end = datetime.now().strftime('%Y-%m-%d')\n",
    "start = (datetime.now() - timedelta(days=5*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "raw = fetcher.fetch(TICKER, start=start, end=end)\n",
    "df = preprocess_ohlcv(raw, market_config=market_config)\n",
    "df = compute_technical_indicators(df)\n",
    "df = compute_return_features(df)\n",
    "df = generate_labels(df, horizon=1, label_type='classification', num_classes=3, threshold=0.01)\n",
    "\n",
    "X, y = get_clean_features_and_labels(df)\n",
    "print(f'Features: {X.shape[1]}, Samples: {len(X)}')\n",
    "print(f'Label distribution:\\n{y.value_counts().sort_index()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adba316",
   "metadata": {},
   "source": [
    "## 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a59942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_selection import (\n",
    "    select_by_importance,\n",
    "    select_by_mutual_info,\n",
    "    filter_correlated,\n",
    "    select_features_pipeline,\n",
    ")\n",
    "\n",
    "# Run the full pipeline: correlation filter → importance ranking\n",
    "selected_features, scores_df = select_features_pipeline(\n",
    "    X, y, max_features=15, corr_threshold=0.90, method='importance'\n",
    ")\n",
    "\n",
    "print(f'\\nSelected {len(selected_features)} features:')\n",
    "for i, f in enumerate(selected_features, 1):\n",
    "    print(f'  {i:2d}. {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec25401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature selection scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# XGBoost importance\n",
    "top_imp = scores_df.nlargest(20, 'xgb_importance')\n",
    "colors = ['#2ecc71' if s else '#95a5a6' for s in top_imp['selected']]\n",
    "axes[0].barh(range(len(top_imp)), top_imp['xgb_importance'].values, color=colors)\n",
    "axes[0].set_yticks(range(len(top_imp)))\n",
    "axes[0].set_yticklabels(top_imp['feature'].values)\n",
    "axes[0].set_title('XGBoost Gain Importance (green = selected)')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Mutual Information\n",
    "top_mi = scores_df.nlargest(20, 'mutual_info')\n",
    "colors2 = ['#3498db' if s else '#95a5a6' for s in top_mi['selected']]\n",
    "axes[1].barh(range(len(top_mi)), top_mi['mutual_info'].values, color=colors2)\n",
    "axes[1].set_yticks(range(len(top_mi)))\n",
    "axes[1].set_yticklabels(top_mi['feature'].values)\n",
    "axes[1].set_title('Mutual Information (blue = selected)')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156442aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also compare with mutual_info method\n",
    "mi_features, mi_scores = select_features_pipeline(\n",
    "    X, y, max_features=15, method='mutual_info'\n",
    ")\n",
    "\n",
    "# Overlap between methods\n",
    "overlap = set(selected_features) & set(mi_features)\n",
    "print(f'Importance-selected: {len(selected_features)}')\n",
    "print(f'MI-selected:         {len(mi_features)}')\n",
    "print(f'Overlap:             {len(overlap)}')\n",
    "print(f'\\nCommon features: {sorted(overlap)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289cc6a",
   "metadata": {},
   "source": [
    "## 3. Baseline: Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b82eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.xgboost_classifier import MarketPulseXGBClassifier\n",
    "from src.utils.validation import WalkForwardValidator\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# Walk-forward evaluation with default params & full features\n",
    "validator = WalkForwardValidator.from_strategy_config(strategy_config)\n",
    "folds = validator.split(X)\n",
    "\n",
    "default_scores = []\n",
    "for fold in folds[-10:]:  # last 10 folds for speed\n",
    "    X_tr, y_tr, X_te, y_te = validator.get_fold_data(X, y, fold)\n",
    "    model = MarketPulseXGBClassifier(num_classes=3)\n",
    "    model.fit(X_tr, y_tr, balance_classes=True)\n",
    "    y_pred = model.predict(X_te)\n",
    "    default_scores.append({\n",
    "        'fold': fold.fold_number,\n",
    "        'accuracy': accuracy_score(y_te.astype(int), y_pred),\n",
    "        'f1_macro': f1_score(y_te.astype(int), y_pred, average='macro', zero_division=0),\n",
    "    })\n",
    "\n",
    "default_df = pd.DataFrame(default_scores)\n",
    "print(f'Default params (full {X.shape[1]} features):')\n",
    "print(f'  Mean accuracy: {default_df[\"accuracy\"].mean():.4f}')\n",
    "print(f'  Mean F1 macro: {default_df[\"f1_macro\"].mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward with default params but SELECTED features\n",
    "X_sel = X[selected_features]\n",
    "\n",
    "selected_scores = []\n",
    "for fold in folds[-10:]:\n",
    "    X_tr, y_tr, X_te, y_te = validator.get_fold_data(X_sel, y, fold)\n",
    "    model = MarketPulseXGBClassifier(num_classes=3)\n",
    "    model.fit(X_tr, y_tr, balance_classes=True)\n",
    "    y_pred = model.predict(X_te)\n",
    "    selected_scores.append({\n",
    "        'fold': fold.fold_number,\n",
    "        'accuracy': accuracy_score(y_te.astype(int), y_pred),\n",
    "        'f1_macro': f1_score(y_te.astype(int), y_pred, average='macro', zero_division=0),\n",
    "    })\n",
    "\n",
    "selected_df = pd.DataFrame(selected_scores)\n",
    "print(f'Default params (selected {len(selected_features)} features):')\n",
    "print(f'  Mean accuracy: {selected_df[\"accuracy\"].mean():.4f}')\n",
    "print(f'  Mean F1 macro: {selected_df[\"f1_macro\"].mean():.4f}')\n",
    "print(f'\\n  Accuracy change: {selected_df[\"accuracy\"].mean() - default_df[\"accuracy\"].mean():+.4f}')\n",
    "print(f'  F1 change:       {selected_df[\"f1_macro\"].mean() - default_df[\"f1_macro\"].mean():+.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3711b2",
   "metadata": {},
   "source": [
    "## 4. Optuna Hyperparameter Tuning\n",
    "\n",
    "Bayesian optimization using TPE (Tree-structured Parzen Estimator).\n",
    "Searches 9 hyperparameter dimensions simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.tuner import MarketPulseTuner, XGBOOST_SEARCH_SPACE\n",
    "\n",
    "tuner = MarketPulseTuner(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    strategy_config=strategy_config,\n",
    "    search_space=XGBOOST_SEARCH_SPACE,\n",
    "    metric='f1_macro',\n",
    "    max_folds=10,\n",
    "    selected_features=selected_features,\n",
    ")\n",
    "\n",
    "# Run 30 trials (takes ~5-15 min depending on machine)\n",
    "best_params = tuner.tune_optuna(n_trials=30, show_progress=True)\n",
    "\n",
    "print(f'\\nBest F1 macro: {tuner.best_score:.4f}')\n",
    "print(f'\\nBest hyperparameters:')\n",
    "for k, v in sorted(best_params.items()):\n",
    "    if k not in ('random_state', 'n_jobs', 'verbosity'):\n",
    "        print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e95b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial history\n",
    "trials_df = tuner.get_results_df()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Score over trials\n",
    "axes[0].plot(trials_df.sort_values('trial')['trial'], \n",
    "             trials_df.sort_values('trial')['score'], \n",
    "             'o-', alpha=0.6, markersize=4)\n",
    "axes[0].axhline(y=tuner.best_score, color='r', linestyle='--', label=f'Best: {tuner.best_score:.4f}')\n",
    "axes[0].axhline(y=default_df['f1_macro'].mean(), color='gray', linestyle=':', label=f'Default: {default_df[\"f1_macro\"].mean():.4f}')\n",
    "axes[0].set_xlabel('Trial')\n",
    "axes[0].set_ylabel('F1 Macro')\n",
    "axes[0].set_title('Optimization Progress')\n",
    "axes[0].legend()\n",
    "\n",
    "# Score distribution\n",
    "axes[1].hist(trials_df['score'].dropna(), bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=tuner.best_score, color='r', linestyle='--', label='Best')\n",
    "axes[1].axvline(x=default_df['f1_macro'].mean(), color='gray', linestyle=':', label='Default')\n",
    "axes[1].set_xlabel('F1 Macro')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Score Distribution Across Trials')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb744775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter importance (which params matter most?)\n",
    "param_imp = tuner.get_param_importance()\n",
    "if param_imp is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    param_imp.plot(kind='barh', ax=ax, color='#3498db')\n",
    "    ax.set_title('Hyperparameter Importance (Optuna)')\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5af98",
   "metadata": {},
   "source": [
    "## 5. Compare Default vs Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc87280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned params with walk-forward\n",
    "X_sel = X[selected_features]\n",
    "tuned_scores = []\n",
    "for fold in folds[-10:]:\n",
    "    X_tr, y_tr, X_te, y_te = validator.get_fold_data(X_sel, y, fold)\n",
    "    model = MarketPulseXGBClassifier(\n",
    "        hyperparameters=best_params, num_classes=3\n",
    "    )\n",
    "    model.fit(X_tr, y_tr, balance_classes=True)\n",
    "    y_pred = model.predict(X_te)\n",
    "    tuned_scores.append({\n",
    "        'fold': fold.fold_number,\n",
    "        'accuracy': accuracy_score(y_te.astype(int), y_pred),\n",
    "        'f1_macro': f1_score(y_te.astype(int), y_pred, average='macro', zero_division=0),\n",
    "    })\n",
    "\n",
    "tuned_df = pd.DataFrame(tuned_scores)\n",
    "\n",
    "# Comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Configuration': ['Default (all features)', f'Default ({len(selected_features)} features)', f'Tuned ({len(selected_features)} features)'],\n",
    "    'Mean Accuracy': [default_df['accuracy'].mean(), selected_df['accuracy'].mean(), tuned_df['accuracy'].mean()],\n",
    "    'Mean F1 Macro': [default_df['f1_macro'].mean(), selected_df['f1_macro'].mean(), tuned_df['f1_macro'].mean()],\n",
    "})\n",
    "comparison['Δ F1 vs Default'] = comparison['Mean F1 Macro'] - comparison['Mean F1 Macro'].iloc[0]\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-fold comparison plot\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "fold_nums = default_df['fold']\n",
    "ax.plot(fold_nums, default_df['f1_macro'], 'o-', label='Default (all features)', alpha=0.7)\n",
    "ax.plot(fold_nums, selected_df['f1_macro'], 's-', label=f'Default ({len(selected_features)} features)', alpha=0.7)\n",
    "ax.plot(fold_nums, tuned_df['f1_macro'], '^-', label=f'Tuned ({len(selected_features)} features)', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Fold')\n",
    "ax.set_ylabel('F1 Macro')\n",
    "ax.set_title('Per-Fold F1 Macro: Default vs Feature-Selected vs Tuned')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bda8e5",
   "metadata": {},
   "source": [
    "## 6. Save Best Configuration\n",
    "\n",
    "Copy the best hyperparameters into your `config/strategies/short_term.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91809cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "print('Best hyperparameters for short_term.yaml:')\n",
    "print()\n",
    "clean_params = {k: round(v, 6) if isinstance(v, float) else v \n",
    "                for k, v in best_params.items() \n",
    "                if k not in ('random_state', 'n_jobs', 'verbosity')}\n",
    "print(yaml.dump({'hyperparameters': clean_params}, default_flow_style=False))\n",
    "print(f'Selected features ({len(selected_features)}):')\n",
    "print(selected_features)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

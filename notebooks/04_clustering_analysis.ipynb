{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afbb2fb",
   "metadata": {},
   "source": [
    "# 04 — Clustering Analysis\n",
    "\n",
    "**MarketPulse Phase 1 — College Requirement: Unsupervised Learning**\n",
    "\n",
    "This notebook segments stocks into behavioral groups using:\n",
    "1. **K-Means** with elbow method and silhouette analysis\n",
    "2. **DBSCAN** as a density-based alternative\n",
    "3. **PCA** for 2D visualization\n",
    "4. Cluster interpretation and profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from src.data.market_config import load_market_config\n",
    "from src.data.fetcher import YFinanceFetcher\n",
    "from src.data.preprocessing import preprocess_ohlcv, preprocess_multiple\n",
    "from src.analysis.clustering import StockClusterAnalyzer\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed53b7",
   "metadata": {},
   "source": [
    "## 1. Fetch Data for Multiple Stocks\n",
    "\n",
    "We need a diverse universe of stocks to see meaningful clusters. We'll use the 14 default stocks from our config plus the benchmark (SPY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313aa85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_market_config('stocks')\n",
    "fetcher = YFinanceFetcher(market_config=config)\n",
    "\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.now() - timedelta(days=5*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch all default tickers\n",
    "tickers = config.default_tickers\n",
    "print(f\"Fetching {len(tickers)} stocks: {tickers}\")\n",
    "\n",
    "raw_data = fetcher.fetch_multiple(tickers, start=start_date, end=end_date)\n",
    "print(f\"\\nFetched: {len(raw_data)} tickers\")\n",
    "\n",
    "# Also fetch benchmark\n",
    "benchmark_raw = fetcher.fetch('SPY', start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2168a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all\n",
    "processed = preprocess_multiple(raw_data, market_config=config)\n",
    "benchmark = preprocess_ohlcv(benchmark_raw, market_config=config)\n",
    "\n",
    "print(f\"Preprocessed: {len(processed)} stocks\")\n",
    "for t, df in processed.items():\n",
    "    print(f\"  {t}: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7c0141",
   "metadata": {},
   "source": [
    "## 2. Compute Behavioral Features\n",
    "\n",
    "For each stock we compute 10 summary statistics that capture its \"personality\":\n",
    "- Return profile (mean return, Sharpe ratio)\n",
    "- Risk profile (volatility, max drawdown)\n",
    "- Market relationship (beta)\n",
    "- Distribution properties (skewness, kurtosis)\n",
    "- Trading characteristics (volume, daily range, up-day ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = StockClusterAnalyzer(benchmark_ticker='SPY')\n",
    "features = analyzer.compute_stock_features(processed, benchmark_data=benchmark)\n",
    "\n",
    "print(f\"Feature matrix shape: {features.shape}\")\n",
    "print(f\"\\nFeatures per stock:\")\n",
    "for col, desc in analyzer.FEATURE_DESCRIPTIONS.items():\n",
    "    print(f\"  {col:20s} — {desc}\")\n",
    "\n",
    "features.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f385ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "for i, col in enumerate(features.columns):\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    features[col].plot(kind='bar', ax=ax, color='steelblue', alpha=0.8)\n",
    "    ax.set_title(col, fontsize=10)\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=7)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Stock Behavioral Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1d99c",
   "metadata": {},
   "source": [
    "## 3. K-Means Clustering\n",
    "\n",
    "### Elbow Method & Silhouette Analysis\n",
    "\n",
    "We try K = 2 through 7 and select the K with the highest silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d64a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, metrics = analyzer.run_kmeans(k_range=range(2, 8))\n",
    "\n",
    "print(f\"\\nOptimal K: {metrics['optimal_k']}\")\n",
    "print(f\"Silhouette score: {metrics['final_silhouette']:.3f}\")\n",
    "\n",
    "# Elbow and silhouette plots\n",
    "fig = analyzer.plot_elbow(metrics)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cluster assignments\n",
    "cluster_assignments = features[['kmeans_cluster']].copy()\n",
    "cluster_assignments['kmeans_cluster'] = cluster_assignments['kmeans_cluster'].astype(int)\n",
    "\n",
    "for cluster_id in sorted(cluster_assignments['kmeans_cluster'].unique()):\n",
    "    members = cluster_assignments[cluster_assignments['kmeans_cluster'] == cluster_id].index.tolist()\n",
    "    print(f\"Cluster {cluster_id}: {members}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049deeef",
   "metadata": {},
   "source": [
    "## 4. PCA Visualization\n",
    "\n",
    "Project the 10-dimensional feature space down to 2 dimensions for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb01e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_coords = analyzer.compute_pca(n_components=2)\n",
    "\n",
    "print(f\"PCA explained variance: {analyzer.pca.explained_variance_ratio_}\")\n",
    "print(f\"Total: {sum(analyzer.pca.explained_variance_ratio_):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Plotly scatter\n",
    "fig = analyzer.plot_clusters_interactive(cluster_col='kmeans_cluster')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96269610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static matplotlib version with labels\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    pca_coords['PC1'], pca_coords['PC2'],\n",
    "    c=pca_coords['kmeans_cluster'],\n",
    "    cmap='Set1', s=150, edgecolors='white', linewidth=1.5, alpha=0.9\n",
    ")\n",
    "\n",
    "# Add ticker labels\n",
    "for ticker, row in pca_coords.iterrows():\n",
    "    ax.annotate(ticker, (row['PC1'], row['PC2']),\n",
    "                fontsize=9, ha='center', va='bottom', \n",
    "                xytext=(0, 8), textcoords='offset points')\n",
    "\n",
    "ax.set_xlabel(f\"PC1 ({analyzer.pca.explained_variance_ratio_[0]:.1%} variance)\")\n",
    "ax.set_ylabel(f\"PC2 ({analyzer.pca.explained_variance_ratio_[1]:.1%} variance)\")\n",
    "ax.set_title('Stock Clusters — PCA Projection', fontsize=14)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ed49c",
   "metadata": {},
   "source": [
    "## 5. DBSCAN Comparison\n",
    "\n",
    "DBSCAN doesn't require specifying K — it finds clusters based on density and marks outliers as noise (-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_labels = analyzer.run_dbscan(eps=1.5, min_samples=2)\n",
    "\n",
    "print(f\"\\nDBSCAN assignments:\")\n",
    "dbscan_df = features[['dbscan_cluster']].copy()\n",
    "for cluster_id in sorted(dbscan_df['dbscan_cluster'].unique()):\n",
    "    members = dbscan_df[dbscan_df['dbscan_cluster'] == cluster_id].index.tolist()\n",
    "    label = 'NOISE' if cluster_id == -1 else f'Cluster {cluster_id}'\n",
    "    print(f\"  {label}: {members}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare K-Means vs DBSCAN side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# K-Means\n",
    "scatter1 = ax1.scatter(pca_coords['PC1'], pca_coords['PC2'],\n",
    "                        c=pca_coords['kmeans_cluster'], cmap='Set1',\n",
    "                        s=150, edgecolors='white', linewidth=1.5)\n",
    "for ticker, row in pca_coords.iterrows():\n",
    "    ax1.annotate(ticker, (row['PC1'], row['PC2']),\n",
    "                fontsize=8, ha='center', va='bottom', xytext=(0, 8), textcoords='offset points')\n",
    "ax1.set_title('K-Means Clustering')\n",
    "ax1.set_xlabel('PC1')\n",
    "ax1.set_ylabel('PC2')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# DBSCAN\n",
    "scatter2 = ax2.scatter(pca_coords['PC1'], pca_coords['PC2'],\n",
    "                        c=pca_coords['dbscan_cluster'], cmap='Set1',\n",
    "                        s=150, edgecolors='white', linewidth=1.5)\n",
    "for ticker, row in pca_coords.iterrows():\n",
    "    ax2.annotate(ticker, (row['PC1'], row['PC2']),\n",
    "                fontsize=8, ha='center', va='bottom', xytext=(0, 8), textcoords='offset points')\n",
    "ax2.set_title('DBSCAN Clustering')\n",
    "ax2.set_xlabel('PC1')\n",
    "ax2.set_ylabel('PC2')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('K-Means vs DBSCAN', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16e500",
   "metadata": {},
   "source": [
    "## 6. Cluster Interpretation\n",
    "\n",
    "What makes each cluster unique? We examine the average feature values per cluster and generate human-readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a790db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = analyzer.interpret_clusters()\n",
    "\n",
    "print(\"Cluster Profiles:\")\n",
    "print(\"=\" * 80)\n",
    "for cluster_id, row in profiles.iterrows():\n",
    "    print(f\"\\nCluster {cluster_id}: {row['suggested_label']} ({int(row['n_stocks'])} stocks)\")\n",
    "    print(f\"  Avg Annual Return:  {row['mean_return']:.1%}\")\n",
    "    print(f\"  Avg Volatility:     {row['volatility']:.1%}\")\n",
    "    print(f\"  Avg Sharpe Ratio:   {row['sharpe_ratio']:.2f}\")\n",
    "    print(f\"  Avg Max Drawdown:   {row['max_drawdown']:.1%}\")\n",
    "    print(f\"  Avg Beta:           {row['beta']:.2f}\")\n",
    "\n",
    "profiles.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee156042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster profile visualization\n",
    "fig = analyzer.plot_cluster_profiles()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710564b2",
   "metadata": {},
   "source": [
    "## 7. Feature Contribution to Clusters\n",
    "\n",
    "Which features are most important in separating the clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA loadings — which original features contribute most to the PCA axes\n",
    "loadings = pd.DataFrame(\n",
    "    analyzer.pca.components_.T,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=features.drop(columns=['kmeans_cluster', 'dbscan_cluster'], errors='ignore').columns\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for i, (feature, row) in enumerate(loadings.iterrows()):\n",
    "    ax.arrow(0, 0, row['PC1']*3, row['PC2']*3,\n",
    "             head_width=0.05, head_length=0.03, fc='steelblue', ec='steelblue', alpha=0.7)\n",
    "    ax.text(row['PC1']*3.2, row['PC2']*3.2, feature, fontsize=9, ha='center')\n",
    "\n",
    "ax.set_xlabel('PC1 Loading')\n",
    "ax.set_ylabel('PC2 Loading')\n",
    "ax.set_title('PCA Loadings — Feature Contributions to Principal Components')\n",
    "ax.axhline(0, color='gray', linewidth=0.5)\n",
    "ax.axvline(0, color='gray', linewidth=0.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474c0172",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **K-Means** identifies interpretable groups — typically separating high-growth/high-vol tech stocks from stable/defensive names.\n",
    "2. **DBSCAN** may identify outlier stocks (e.g., TSLA often stands alone due to extreme volatility).\n",
    "3. **PCA** shows that volatility and beta dominate the first principal component, while return and Sharpe separate stocks on the second.\n",
    "4. **Cluster labels** (Growth, Defensive, High-Volatility, etc.) are auto-generated based on feature thresholds.\n",
    "\n",
    "**College requirement satisfied**: We demonstrated K-Means, DBSCAN, and PCA with financial interpretation.\n",
    "\n",
    "**Practical use**: Clustering can inform:\n",
    "- Portfolio diversification (don't over-concentrate in one cluster)\n",
    "- Strategy adaptation (different model parameters per cluster)\n",
    "- Risk management (monitor cluster shifts over time)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

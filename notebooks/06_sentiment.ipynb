{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262f580e",
   "metadata": {},
   "source": [
    "# 06 — Sentiment Analysis (Phase 2)\n",
    "\n",
    "This notebook demonstrates the full Phase 2 sentiment pipeline:\n",
    "1. Fetch financial news from multiple sources\n",
    "2. Score headlines with FinBERT\n",
    "3. Aggregate into daily sentiment features\n",
    "4. Merge with price data and evaluate impact on predictions\n",
    "\n",
    "**Prerequisites:** `pip install transformers torch newsapi-python requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b022a6d",
   "metadata": {},
   "source": [
    "## 1. Fetch News Headlines\n",
    "\n",
    "We use 3 sources (all free):\n",
    "- **yfinance**: built-in, ~10-15 recent headlines\n",
    "- **GDELT**: 3-month history, unlimited API\n",
    "- **NewsAPI** (optional): needs free key from newsapi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.news_fetcher import (\n",
    "    YFinanceNewsFetcher,\n",
    "    GDELTNewsFetcher,\n",
    "    AggregateNewsFetcher,\n",
    ")\n",
    "\n",
    "TICKER = 'AAPL'\n",
    "COMPANY = 'Apple'  # Broader search term for news APIs\n",
    "\n",
    "# Individual sources\n",
    "yf_fetcher = YFinanceNewsFetcher()\n",
    "yf_news = yf_fetcher.fetch_news(TICKER)\n",
    "print(f'yfinance: {len(yf_news)} headlines')\n",
    "for item in yf_news[:3]:\n",
    "    print(f'  [{item[\"source\"]}] {item[\"title\"][:80]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c28e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdelt_fetcher = GDELTNewsFetcher()\n",
    "gdelt_news = gdelt_fetcher.fetch_news(\n",
    "    COMPANY, \n",
    "    start_date=(datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d'),\n",
    "    max_results=50\n",
    ")\n",
    "print(f'GDELT: {len(gdelt_news)} headlines')\n",
    "for item in gdelt_news[:3]:\n",
    "    print(f'  [{item[\"source\"]}] {item[\"title\"][:80]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all sources\n",
    "# Set your NewsAPI key here (optional — get free at newsapi.org/register)\n",
    "NEWSAPI_KEY = None  # e.g. 'your_key_here'\n",
    "\n",
    "agg_fetcher = AggregateNewsFetcher(newsapi_key=NEWSAPI_KEY, use_gdelt=True)\n",
    "news_df = agg_fetcher.fetch_all(\n",
    "    query=COMPANY,\n",
    "    start_date=(datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d'),\n",
    ")\n",
    "\n",
    "print(f'\\nTotal unique headlines: {len(news_df)}')\n",
    "print(f'Sources: {news_df[\"source\"].value_counts().to_dict()}')\n",
    "news_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585416c",
   "metadata": {},
   "source": [
    "## 2. FinBERT Sentiment Scoring\n",
    "\n",
    "FinBERT (ProsusAI/finbert) classifies each headline as:\n",
    "- **Positive** (+1.0): bullish sentiment\n",
    "- **Negative** (-1.0): bearish sentiment  \n",
    "- **Neutral** (0.0): no directional signal\n",
    "\n",
    "First run downloads ~420 MB model (cached locally after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.sentiment import FinBERTSentimentScorer\n",
    "\n",
    "scorer = FinBERTSentimentScorer(device='cpu')  # 'cuda' if you have GPU\n",
    "\n",
    "# Score all headlines\n",
    "scored_df = scorer.score_dataframe(news_df)\n",
    "\n",
    "print(f'Scored {len(scored_df)} headlines')\n",
    "print(f'\\nSentiment distribution:')\n",
    "print(scored_df['sentiment_label'].value_counts())\n",
    "print(f'\\nMean sentiment score: {scored_df[\"sentiment_score\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c60819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some scored headlines\n",
    "display_cols = ['title', 'sentiment_label', 'sentiment_score', 'confidence']\n",
    "\n",
    "print('\\n--- Most POSITIVE headlines ---')\n",
    "pos = scored_df[scored_df['sentiment_label'] == 'positive'].nlargest(5, 'confidence')\n",
    "for _, row in pos.iterrows():\n",
    "    print(f'  [{row[\"confidence\"]:.2f}] {row[\"title\"][:90]}')\n",
    "\n",
    "print('\\n--- Most NEGATIVE headlines ---')\n",
    "neg = scored_df[scored_df['sentiment_label'] == 'negative'].nlargest(5, 'confidence')\n",
    "for _, row in neg.iterrows():\n",
    "    print(f'  [{row[\"confidence\"]:.2f}] {row[\"title\"][:90]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ab65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "counts = scored_df['sentiment_label'].value_counts()\n",
    "colors = {'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#95a5a6'}\n",
    "axes[0].pie(\n",
    "    counts.values, labels=counts.index, \n",
    "    colors=[colors.get(l, '#ccc') for l in counts.index],\n",
    "    autopct='%1.1f%%', startangle=90\n",
    ")\n",
    "axes[0].set_title(f'Sentiment Distribution ({COMPANY})')\n",
    "\n",
    "# Confidence histogram\n",
    "for label in ['positive', 'negative', 'neutral']:\n",
    "    subset = scored_df[scored_df['sentiment_label'] == label]\n",
    "    if not subset.empty:\n",
    "        axes[1].hist(subset['confidence'], bins=20, alpha=0.6, \n",
    "                     label=label, color=colors.get(label, '#ccc'))\n",
    "axes[1].set_xlabel('Confidence')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('FinBERT Confidence Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d28373",
   "metadata": {},
   "source": [
    "## 3. Daily Sentiment Aggregation\n",
    "\n",
    "Convert per-headline scores into daily trading features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.sentiment import aggregate_daily_sentiment\n",
    "\n",
    "daily_sentiment = aggregate_daily_sentiment(scored_df)\n",
    "print(f'Daily sentiment features: {daily_sentiment.shape}')\n",
    "daily_sentiment.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily sentiment over time\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Mean sentiment\n",
    "axes[0].bar(daily_sentiment.index, daily_sentiment['sentiment_mean'],\n",
    "            color=['#2ecc71' if x > 0 else '#e74c3c' for x in daily_sentiment['sentiment_mean']],\n",
    "            alpha=0.7)\n",
    "axes[0].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[0].set_ylabel('Mean Sentiment')\n",
    "axes[0].set_title(f'Daily Sentiment Features — {COMPANY}')\n",
    "\n",
    "# Positive / negative ratio\n",
    "axes[1].fill_between(daily_sentiment.index, daily_sentiment['sentiment_positive_ratio'],\n",
    "                     alpha=0.5, color='#2ecc71', label='Positive ratio')\n",
    "axes[1].fill_between(daily_sentiment.index, -daily_sentiment['sentiment_negative_ratio'],\n",
    "                     alpha=0.5, color='#e74c3c', label='Negative ratio')\n",
    "axes[1].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[1].set_ylabel('Sentiment Ratio')\n",
    "axes[1].legend()\n",
    "\n",
    "# News volume & momentum\n",
    "axes[2].bar(daily_sentiment.index, daily_sentiment['sentiment_count'],\n",
    "            alpha=0.4, color='gray', label='Headline count')\n",
    "ax2 = axes[2].twinx()\n",
    "ax2.plot(daily_sentiment.index, daily_sentiment['sentiment_momentum_5d'],\n",
    "         color='blue', linewidth=2, label='5d Momentum')\n",
    "axes[2].set_ylabel('Headlines')\n",
    "ax2.set_ylabel('5d Sentiment Momentum')\n",
    "axes[2].legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36209b2",
   "metadata": {},
   "source": [
    "## 4. Merge with Price Data & Evaluate Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc745586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.fetcher import YFinanceFetcher\n",
    "from src.data.preprocessing import preprocess_ohlcv\n",
    "from src.features.technical import compute_technical_indicators\n",
    "from src.features.returns import compute_return_features\n",
    "from src.features.labels import generate_labels, get_clean_features_and_labels\n",
    "from src.features.sentiment import merge_sentiment_features\n",
    "from src.data.market_config import load_market_config, load_strategy_config\n",
    "\n",
    "market_config = load_market_config('stocks')\n",
    "strategy_config = load_strategy_config('short_term')\n",
    "\n",
    "# Fetch price data\n",
    "fetcher = YFinanceFetcher()\n",
    "end = datetime.now().strftime('%Y-%m-%d')\n",
    "start = (datetime.now() - timedelta(days=5*365)).strftime('%Y-%m-%d')\n",
    "\n",
    "raw = fetcher.fetch(TICKER, start=start, end=end)\n",
    "df = preprocess_ohlcv(raw, market_config=market_config)\n",
    "df = compute_technical_indicators(df)\n",
    "df = compute_return_features(df)\n",
    "\n",
    "# Merge sentiment\n",
    "df = merge_sentiment_features(df, daily_sentiment)\n",
    "\n",
    "# Labels\n",
    "df = generate_labels(df, horizon=1, label_type='classification', num_classes=3, threshold=0.01)\n",
    "X, y = get_clean_features_and_labels(df)\n",
    "\n",
    "print(f'Features: {X.shape[1]} (technical + return + sentiment)')\n",
    "sentiment_cols = [c for c in X.columns if 'sentiment' in c]\n",
    "print(f'Sentiment features: {sentiment_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceef7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: with vs without sentiment features\n",
    "from src.models.xgboost_classifier import MarketPulseXGBClassifier\n",
    "from src.utils.validation import WalkForwardValidator\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "validator = WalkForwardValidator.from_strategy_config(strategy_config)\n",
    "folds = validator.split(X)\n",
    "\n",
    "# Without sentiment\n",
    "X_no_sent = X.drop(columns=sentiment_cols, errors='ignore')\n",
    "scores_no = []\n",
    "for fold in folds[-10:]:\n",
    "    X_tr, y_tr, X_te, y_te = validator.get_fold_data(X_no_sent, y, fold)\n",
    "    m = MarketPulseXGBClassifier(num_classes=3)\n",
    "    m.fit(X_tr, y_tr, balance_classes=True)\n",
    "    pred = m.predict(X_te)\n",
    "    scores_no.append(f1_score(y_te.astype(int), pred, average='macro', zero_division=0))\n",
    "\n",
    "# With sentiment\n",
    "scores_with = []\n",
    "for fold in folds[-10:]:\n",
    "    X_tr, y_tr, X_te, y_te = validator.get_fold_data(X, y, fold)\n",
    "    m = MarketPulseXGBClassifier(num_classes=3)\n",
    "    m.fit(X_tr, y_tr, balance_classes=True)\n",
    "    pred = m.predict(X_te)\n",
    "    scores_with.append(f1_score(y_te.astype(int), pred, average='macro', zero_division=0))\n",
    "\n",
    "print(f'Without sentiment: F1 = {np.mean(scores_no):.4f}')\n",
    "print(f'With sentiment:    F1 = {np.mean(scores_with):.4f}')\n",
    "print(f'Delta:             {np.mean(scores_with) - np.mean(scores_no):+.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702cc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment feature importance in the model\n",
    "model = MarketPulseXGBClassifier(num_classes=3)\n",
    "model.fit(X, y, balance_classes=True)\n",
    "importance = model.get_feature_importance()\n",
    "\n",
    "# Highlight sentiment features\n",
    "top20 = importance.head(20)\n",
    "colors = ['#e74c3c' if 'sentiment' in f else '#3498db' for f in top20.index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.barh(range(len(top20)), top20.values, color=colors)\n",
    "ax.set_yticks(range(len(top20)))\n",
    "ax.set_yticklabels(top20.index)\n",
    "ax.set_title('Top 20 Feature Importance (red = sentiment)')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c58e31",
   "metadata": {},
   "source": [
    "## 5. Sentiment Surprise as a Trading Signal\n",
    "\n",
    "**Sentiment surprise** = today's sentiment − 5-day rolling mean.\n",
    "\n",
    "A large positive surprise means unexpectedly bullish news → potential UP signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment surprise vs next-day returns\n",
    "if 'sentiment_surprise' in df.columns and 'fwd_return_1d' in df.columns:\n",
    "    analysis = df[['sentiment_surprise', 'fwd_return_1d']].dropna()\n",
    "    \n",
    "    if len(analysis) > 10:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Scatter\n",
    "        axes[0].scatter(analysis['sentiment_surprise'], analysis['fwd_return_1d'],\n",
    "                        alpha=0.3, s=10)\n",
    "        axes[0].set_xlabel('Sentiment Surprise')\n",
    "        axes[0].set_ylabel('Next-Day Return')\n",
    "        axes[0].set_title('Sentiment Surprise vs Forward Return')\n",
    "        \n",
    "        # Bucketed analysis\n",
    "        analysis['surprise_bucket'] = pd.qcut(\n",
    "            analysis['sentiment_surprise'], q=5, labels=['Very Neg', 'Neg', 'Neutral', 'Pos', 'Very Pos'],\n",
    "            duplicates='drop'\n",
    "        )\n",
    "        bucket_returns = analysis.groupby('surprise_bucket')['fwd_return_1d'].mean()\n",
    "        bucket_returns.plot(kind='bar', ax=axes[1], color='#3498db')\n",
    "        axes[1].set_xlabel('Sentiment Surprise Quintile')\n",
    "        axes[1].set_ylabel('Mean Next-Day Return')\n",
    "        axes[1].set_title('Forward Returns by Sentiment Surprise Quintile')\n",
    "        axes[1].tick_params(axis='x', rotation=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Not enough overlapping data between sentiment and returns.')\n",
    "else:\n",
    "    print('Columns not available. This works best with more news history.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0751cfa",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Phase 2 adds 8 sentiment features** to the model:\n",
    "- `sentiment_mean/std`: daily polarity and dispersion\n",
    "- `sentiment_positive/negative_ratio`: bullish/bearish headline percentages\n",
    "- `sentiment_count`: news volume (more volume often = more volatility)\n",
    "- `sentiment_momentum_3d/5d`: rolling sentiment trends\n",
    "- `sentiment_surprise`: contrarian signal (unexpected shifts)\n",
    "\n",
    "**Usage in production:**\n",
    "```python\n",
    "python -m src.models.trainer --tickers AAPL --sentiment\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
